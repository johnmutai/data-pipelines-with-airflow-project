# -*- coding: utf-8 -*-
"""Data Pipelines with Airflow Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12Ofa2WxP3lZ_42ZzePK9KyQ9H14lTLvg
"""

import airflow
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from datetime import datetime, timedelta
import pandas as pd

default_args = {
    'owner': 'MTN Rwanda',
    'depends_on_past': False,
    'start_date': datetime(2023, 4, 19),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5)
}    

dag = DAG('data_pipeline', default_args=default_args, schedule_interval='@daily')

def extract_data():
  # extract data from CSV files and load the CSV data into Pandas dataframes for later transformation
  customer_df = pd.read_csv('customer_data.csv')
  order_df = pd.read_csv('order_data.csv')
  payment_df = pd.read_csv('payment_data')

  return customer_df, order_df, payment_df


def transform_data(customer_df, order_df, payment_df):

  extract_data()
  
  # convert date fields to the correct format using pd.to_datetime
  customer_df["date_of_birth"] = pd.to_datetime(customer_df["date_of_birth"])
  order_df['order_date'] = pd.to_datetime(order_df['order_date'])
  payment_df['payment_date'] = pd.to_datetime(payment_df['payment_date'])
  
  # merge customer and order dataframes on the customer_id column
  customer_data = pd.merge(customer_df, order_df, on=['customer_id'])
  
  # merge payment dataframe with the merged dataframe on the order_id and customer_id columns
  customer_data = pd.merge(customer_data, payment_df, on=['customer_id'])

  # drop unnecessary columns like customer_id and order_id
  customer_data.drop(columns = ['customer_id', 'order_id_x', 'order_id_y'], inplace=True)

  return customer_data


 # define function to load the transformed data into Postgres database

def load_data(transformed_data):
    # Connect to Postgres database
    conn = psycopg2.connect(host="35.233.221.160", database="mydbs1", user="studentj", password="minimum7467!")

    # Create a cursor object
    cur = conn.cursor()

    # Create a table to store the data
    cur.execute('''CREATE TABLE IF NOT EXISTS customer_orders (
                 first_name VARCHAR,
                 last_name VARCHAR,
                 email VARCHAR,
                 country VARCHAR,
                 gender VARCHAR
                 date_of_birth TIMESTAMP
                 order_date TIMESTAMP
                 product VARCHAR
                 price FLOAT
                 payment_id INT
                 payment_date TIMESTAMP
                 amount FLOAT
                 )''')

    # Insert the transformed data into the database
    for i, row in transformed_data.iterrows():
        cur.execute(f"INSERT INTO customer_orders (first_name, last_name, email, country, gender, date_of_birth, order_date, product, price, payment_id, payment_date, amount) VALUES ({row['first_name']}, {row['last_name']}, '{row['email']}', '{row['country']}', {row['gender']}, {row['date_of_birth']}, {row['order_date']}, {row['product']}, {row['price']}, {row['payment_id']}, {row['payment_date']}, {row['amount']})")

    # Commit the changes
    conn.commit()

    # Close the cursor and connection
    cur.close()
    conn.close() 


 extract_task = PythonOperator(
    task_id='extract_data',
    python_callable=extract_data,
    dag=dag
)

transform_task = PythonOperator(
    task_id='transform_data',
    python_callable=transform_data,
    dag=dag
)

load_task = PythonOperator(
    task_id='load_data',
    python_callable=load_data,
    op_kwargs={'customer_data': transform_task.output},
    dag=dag
)

# set task dependencies
extract_task >> transform_task >> load_task